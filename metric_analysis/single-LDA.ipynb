{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: 蓝色思考帽(管理)\n",
      "Topic 0: 0.154*\"思考\" + 0.032*\"客观\" + 0.032*\"情感\" + 0.032*\"讨论\" + 0.032*\"职业\" + 0.024*\"红色\" + 0.024*\"黑色\" + 0.024*\"创新\" + 0.024*\"应对\" + 0.024*\"黄色\"\n",
      "Topic 1: 0.010*\"思考\" + 0.010*\"客观\" + 0.010*\"情感\" + 0.010*\"红色\" + 0.010*\"职业\" + 0.010*\"顺序\" + 0.010*\"创新\" + 0.010*\"白色\" + 0.010*\"表达\" + 0.010*\"讨论\"\n",
      "Topic 2: 0.156*\"思考\" + 0.058*\"情感\" + 0.044*\"客观\" + 0.030*\"顺序\" + 0.030*\"黑色\" + 0.030*\"白色\" + 0.030*\"红色\" + 0.030*\"黄色\" + 0.030*\"批判\" + 0.030*\"创新\"\n",
      "Topic 3: 0.119*\"思考\" + 0.030*\"客观\" + 0.026*\"职业\" + 0.026*\"挑战\" + 0.026*\"创新\" + 0.026*\"顺序\" + 0.025*\"情感\" + 0.021*\"过程\" + 0.021*\"绿色\" + 0.021*\"提出\"\n",
      "Topic 4: 0.010*\"思考\" + 0.010*\"挑战\" + 0.010*\"客观\" + 0.010*\"绿色\" + 0.010*\"创新\" + 0.010*\"情感\" + 0.010*\"红色\" + 0.010*\"职业\" + 0.010*\"顺序\" + 0.010*\"提出\"\n",
      "\n",
      "\n",
      "Agent: 红色思考帽(情感)\n",
      "Topic 0: 0.008*\"尝试\" + 0.008*\"正位\" + 0.008*\"情感\" + 0.008*\"改变\" + 0.008*\"思考\" + 0.008*\"审视\" + 0.008*\"寻求\" + 0.008*\"面对\" + 0.008*\"代表\" + 0.008*\"未来\"\n",
      "Topic 1: 0.041*\"思考\" + 0.033*\"情感\" + 0.033*\"审视\" + 0.033*\"适合\" + 0.033*\"感受\" + 0.025*\"面对\" + 0.025*\"挑战\" + 0.025*\"改变\" + 0.025*\"确实\" + 0.025*\"期望\"\n",
      "Topic 2: 0.058*\"死神\" + 0.042*\"机会\" + 0.034*\"面对\" + 0.026*\"感到\" + 0.026*\"接受\" + 0.026*\"寻求\" + 0.026*\"变化\" + 0.018*\"目标\" + 0.018*\"思考\" + 0.018*\"支持\"\n",
      "Topic 3: 0.008*\"尝试\" + 0.008*\"寻求\" + 0.008*\"正位\" + 0.008*\"思考\" + 0.008*\"改变\" + 0.008*\"情感\" + 0.008*\"未来\" + 0.008*\"面对\" + 0.008*\"确实\" + 0.008*\"希望\"\n",
      "Topic 4: 0.044*\"尝试\" + 0.031*\"寻求\" + 0.031*\"正位\" + 0.025*\"思考\" + 0.025*\"挑战\" + 0.025*\"审视\" + 0.025*\"面对\" + 0.025*\"希望\" + 0.025*\"情感\" + 0.025*\"未来\"\n",
      "\n",
      "\n",
      "Agent: 黄色思考帽(积极)\n",
      "Topic 0: 0.008*\"尝试\" + 0.008*\"挑战\" + 0.008*\"情感\" + 0.008*\"需求\" + 0.008*\"感到\" + 0.008*\"识别\" + 0.008*\"学会\" + 0.008*\"释放\" + 0.008*\"困难\" + 0.008*\"心态\"\n",
      "Topic 1: 0.072*\"职业\" + 0.033*\"建议\" + 0.033*\"应对\" + 0.033*\"机会\" + 0.033*\"寻找\" + 0.025*\"工作\" + 0.025*\"朋友\" + 0.025*\"支持\" + 0.025*\"过程\" + 0.025*\"计划\"\n",
      "Topic 2: 0.029*\"建议\" + 0.029*\"心态\" + 0.029*\"目标\" + 0.020*\"挑战\" + 0.020*\"寻求\" + 0.020*\"尝试\" + 0.020*\"应对\" + 0.020*\"支持\" + 0.020*\"朋友\" + 0.020*\"生活\"\n",
      "Topic 3: 0.008*\"职业\" + 0.008*\"建议\" + 0.008*\"支持\" + 0.008*\"应对\" + 0.008*\"心态\" + 0.008*\"寻求\" + 0.008*\"朋友\" + 0.008*\"过程\" + 0.008*\"挑战\" + 0.008*\"尝试\"\n",
      "Topic 4: 0.038*\"尝试\" + 0.038*\"挑战\" + 0.031*\"情感\" + 0.024*\"感到\" + 0.024*\"需求\" + 0.016*\"心态\" + 0.016*\"建议\" + 0.016*\"暂时\" + 0.016*\"培养\" + 0.016*\"生活\"\n",
      "\n",
      "\n",
      "Agent: 绿色思考帽(创新)\n",
      "Topic 0: 0.058*\"职业\" + 0.034*\"过程\" + 0.034*\"参加\" + 0.034*\"建立\" + 0.026*\"提供\" + 0.026*\"经验\" + 0.026*\"跨界\" + 0.018*\"工作\" + 0.018*\"机会\" + 0.018*\"创新\"\n",
      "Topic 1: 0.008*\"方式\" + 0.008*\"寻找\" + 0.008*\"职业\" + 0.008*\"工作\" + 0.008*\"机会\" + 0.008*\"建议\" + 0.008*\"过程\" + 0.008*\"思维\" + 0.008*\"沟通\" + 0.008*\"审视\"\n",
      "Topic 2: 0.043*\"职业\" + 0.035*\"领域\" + 0.035*\"过程\" + 0.027*\"品牌\" + 0.027*\"机会\" + 0.027*\"发展\" + 0.027*\"学习\" + 0.027*\"创业\" + 0.027*\"自立\" + 0.027*\"岗位\"\n",
      "Topic 3: 0.008*\"职业\" + 0.008*\"过程\" + 0.008*\"建立\" + 0.008*\"经验\" + 0.008*\"跨界\" + 0.008*\"提供\" + 0.008*\"尝试\" + 0.008*\"参加\" + 0.008*\"机会\" + 0.008*\"朋友\"\n",
      "Topic 4: 0.073*\"寻找\" + 0.066*\"方式\" + 0.047*\"工作\" + 0.047*\"思维\" + 0.047*\"建议\" + 0.034*\"沟通\" + 0.027*\"机会\" + 0.027*\"风险\" + 0.027*\"改变\" + 0.027*\"审视\"\n",
      "\n",
      "\n",
      "Agent: 黑色思考帽(批判)\n",
      "Topic 0: 0.008*\"占卜\" + 0.008*\"带来\" + 0.008*\"改变\" + 0.008*\"确保\" + 0.008*\"情况\" + 0.008*\"建议\" + 0.008*\"提供\" + 0.008*\"挑战\" + 0.008*\"方式\" + 0.008*\"工作\"\n",
      "Topic 1: 0.008*\"职业\" + 0.008*\"过程\" + 0.008*\"规划\" + 0.008*\"阶段\" + 0.008*\"适合\" + 0.008*\"合作\" + 0.008*\"心态\" + 0.008*\"沟通\" + 0.008*\"变化\" + 0.008*\"技能\"\n",
      "Topic 2: 0.046*\"改变\" + 0.039*\"占卜\" + 0.033*\"挑战\" + 0.027*\"正位\" + 0.027*\"提供\" + 0.027*\"建议\" + 0.027*\"确保\" + 0.027*\"情况\" + 0.020*\"找到\" + 0.020*\"思考\"\n",
      "Topic 3: 0.040*\"职业\" + 0.034*\"过程\" + 0.027*\"规划\" + 0.021*\"适合\" + 0.021*\"面对\" + 0.021*\"心态\" + 0.021*\"调适\" + 0.021*\"耐心\" + 0.021*\"提升\" + 0.021*\"环境\"\n",
      "Topic 4: 0.008*\"改变\" + 0.008*\"占卜\" + 0.008*\"正位\" + 0.008*\"确保\" + 0.008*\"挑战\" + 0.008*\"情况\" + 0.008*\"建议\" + 0.008*\"提供\" + 0.008*\"找到\" + 0.008*\"思考\"\n",
      "\n",
      "\n",
      "Agent: 白色思考帽(客观)\n",
      "Topic 0: 0.016*\"生活\" + 0.016*\"寻找\" + 0.016*\"改变\" + 0.016*\"方向\" + 0.016*\"占卜\" + 0.016*\"情感\" + 0.016*\"挑战\" + 0.016*\"心态\" + 0.016*\"审视\" + 0.016*\"提供\"\n",
      "Topic 1: 0.042*\"生活\" + 0.032*\"改变\" + 0.032*\"情感\" + 0.032*\"挑战\" + 0.032*\"审视\" + 0.032*\"方向\" + 0.032*\"寻找\" + 0.032*\"占卜\" + 0.032*\"心态\" + 0.021*\"寻求\"\n",
      "Topic 2: 0.016*\"生活\" + 0.016*\"心态\" + 0.016*\"占卜\" + 0.016*\"挑战\" + 0.016*\"审视\" + 0.016*\"方向\" + 0.016*\"情感\" + 0.016*\"寻找\" + 0.016*\"工作\" + 0.016*\"决策\"\n",
      "Topic 3: 0.016*\"寻找\" + 0.016*\"生活\" + 0.016*\"方向\" + 0.016*\"改变\" + 0.016*\"情感\" + 0.016*\"审视\" + 0.016*\"尝试\" + 0.016*\"挑战\" + 0.016*\"占卜\" + 0.016*\"寻求\"\n",
      "Topic 4: 0.016*\"生活\" + 0.016*\"改变\" + 0.016*\"方向\" + 0.016*\"占卜\" + 0.016*\"心态\" + 0.016*\"情感\" + 0.016*\"审视\" + 0.016*\"寻找\" + 0.016*\"挑战\" + 0.016*\"方式\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import json\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import numpy as np\n",
    "\n",
    "# 读取conversation_history.json文件\n",
    "with open('/data1/dxw_data/llm/is_agents/agents/six_hats/task5/conversation_history.json', 'r', encoding='utf-8') as file:\n",
    "    conversation_data = json.load(file)\n",
    "\n",
    "# 停用词表\n",
    "stop_words = set()\n",
    "with open('/data1/dxw_data/llm/ML/LIWC/datasets/stopwords_cn.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        stop_words.add(line.strip())\n",
    "\n",
    "# 文本预处理函数\n",
    "def preprocess(text):\n",
    "    tokens = jieba.lcut(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) == 2 and word.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "# 对conversation_data中的每个agent的message进行分类\n",
    "agent_messages = {}\n",
    "for conversation in conversation_data:\n",
    "    agent = conversation['agent']\n",
    "    message = conversation['message']\n",
    "    if agent not in agent_messages:\n",
    "        agent_messages[agent] = []\n",
    "    agent_messages[agent].append(message)\n",
    "\n",
    "# 对每个agent的message进行LDA分析并将结果写入文件\n",
    "def lda_analysis(agent, messages, num_topics=5, file=None):\n",
    "    # 对消息进行预处理\n",
    "    processed_texts = [preprocess(message) for message in messages]\n",
    "    \n",
    "    # 创建词典和语料库\n",
    "    dictionary = corpora.Dictionary(processed_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "    \n",
    "    # 构建LDA模型\n",
    "    lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    \n",
    "    # 打印并保存该agent的主题\n",
    "    result = f\"\\nAgent: {agent}\\n\"\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        result += f\"Topic {idx}: {topic}\\n\"\n",
    "    \n",
    "    # 打印结果到控制台\n",
    "    print(result)\n",
    "    \n",
    "    # 将结果写入文件\n",
    "    if file:\n",
    "        file.write(result)\n",
    "\n",
    "# 打开文件进行写入\n",
    "with open('/data1/dxw_data/llm/is_agents/agents/six_hats/task5/log_lda1.txt', 'w', encoding='utf-8') as log_file:\n",
    "    for agent, messages in agent_messages.items():\n",
    "        if len(messages) > 1:  # 如果该agent有多条消息，则进行LDA分析\n",
    "            lda_analysis(agent, messages, file=log_file)\n",
    "        else:\n",
    "            no_analysis_message = f\"\\nAgent: {agent} 没有足够的消息进行LDA分析\\n\"\n",
    "            print(no_analysis_message)\n",
    "            log_file.write(no_analysis_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: 蓝色思考帽(管理)\n",
      "Topic: (0, '0.135*\"思考\" + 0.053*\"情感\" + 0.041*\"客观\" + 0.029*\"白色\" + 0.029*\"黑色\"')\n",
      "\n",
      "\n",
      "Agent: 红色思考帽(情感)\n",
      "Topic: (0, '0.036*\"尝试\" + 0.027*\"正位\" + 0.027*\"寻求\" + 0.023*\"未来\" + 0.023*\"审视\"')\n",
      "\n",
      "\n",
      "Agent: 黄色思考帽(积极)\n",
      "Topic: (0, '0.033*\"尝试\" + 0.033*\"挑战\" + 0.027*\"情感\" + 0.022*\"需求\" + 0.022*\"感到\"')\n",
      "\n",
      "\n",
      "Agent: 绿色思考帽(创新)\n",
      "Topic: (0, '0.065*\"寻找\" + 0.059*\"方式\" + 0.043*\"思维\" + 0.043*\"工作\" + 0.043*\"建议\"')\n",
      "\n",
      "\n",
      "Agent: 黑色思考帽(批判)\n",
      "Topic: (0, '0.036*\"改变\" + 0.029*\"挑战\" + 0.029*\"正位\" + 0.029*\"占卜\" + 0.022*\"找到\"')\n",
      "\n",
      "\n",
      "Agent: 白色思考帽(客观)\n",
      "Topic: (0, '0.032*\"生活\" + 0.025*\"心态\" + 0.025*\"挑战\" + 0.025*\"占卜\" + 0.025*\"情感\"')\n",
      "\n",
      "\n",
      "Agent: 蓝色思考帽(管理)\n",
      "Topic: (0, '0.094*\"思考\" + 0.026*\"客观\" + 0.023*\"挑战\" + 0.023*\"职业\" + 0.023*\"顺序\"')\n",
      "\n",
      "\n",
      "Agent: 白色思考帽(客观)\n",
      "Topic: (0, '0.032*\"生活\" + 0.025*\"心态\" + 0.025*\"挑战\" + 0.025*\"占卜\" + 0.025*\"情感\"')\n",
      "\n",
      "\n",
      "Agent: 红色思考帽(情感)\n",
      "Topic: (0, '0.036*\"思考\" + 0.030*\"审视\" + 0.030*\"适合\" + 0.030*\"感受\" + 0.030*\"情感\"')\n",
      "\n",
      "\n",
      "Agent: 黄色思考帽(积极)\n",
      "Topic: (0, '0.063*\"职业\" + 0.031*\"建议\" + 0.031*\"应对\" + 0.031*\"机会\" + 0.031*\"寻找\"')\n",
      "\n",
      "\n",
      "Agent: 黑色思考帽(批判)\n",
      "Topic: (0, '0.038*\"占卜\" + 0.038*\"改变\" + 0.029*\"带来\" + 0.029*\"情况\" + 0.029*\"建议\"')\n",
      "\n",
      "\n",
      "Agent: 绿色思考帽(创新)\n",
      "Topic: (0, '0.050*\"职业\" + 0.031*\"参加\" + 0.031*\"过程\" + 0.031*\"建立\" + 0.025*\"跨界\"')\n",
      "\n",
      "\n",
      "Agent: 蓝色思考帽(管理)\n",
      "Topic: (0, '0.127*\"思考\" + 0.030*\"职业\" + 0.030*\"讨论\" + 0.030*\"客观\" + 0.030*\"情感\"')\n",
      "\n",
      "\n",
      "Agent: 白色思考帽(客观)\n",
      "Topic: (0, '0.032*\"生活\" + 0.025*\"心态\" + 0.025*\"挑战\" + 0.025*\"占卜\" + 0.025*\"情感\"')\n",
      "\n",
      "\n",
      "Agent: 红色思考帽(情感)\n",
      "Topic: (0, '0.050*\"死神\" + 0.037*\"机会\" + 0.031*\"面对\" + 0.025*\"寻求\" + 0.025*\"感到\"')\n",
      "\n",
      "\n",
      "Agent: 黄色思考帽(积极)\n",
      "Topic: (0, '0.027*\"建议\" + 0.027*\"心态\" + 0.027*\"目标\" + 0.020*\"心理\" + 0.020*\"健康\"')\n",
      "\n",
      "\n",
      "Agent: 黑色思考帽(批判)\n",
      "Topic: (0, '0.034*\"职业\" + 0.029*\"过程\" + 0.024*\"规划\" + 0.020*\"技能\" + 0.020*\"耐心\"')\n",
      "\n",
      "\n",
      "Agent: 绿色思考帽(创新)\n",
      "Topic: (0, '0.040*\"职业\" + 0.033*\"过程\" + 0.033*\"领域\" + 0.026*\"学习\" + 0.026*\"机会\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import json\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import numpy as np\n",
    "\n",
    "# 读取conversation_history.json文件\n",
    "with open('/data1/dxw_data/llm/is_agents/agents/six_hats/task5/conversation_history.json', 'r', encoding='utf-8') as file:\n",
    "    conversation_data = json.load(file)\n",
    "\n",
    "# 停用词表\n",
    "stop_words = set()\n",
    "with open('/data1/dxw_data/llm/ML/LIWC/datasets/stopwords_cn.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        stop_words.add(line.strip())\n",
    "\n",
    "# 文本预处理函数\n",
    "def preprocess(text):\n",
    "    tokens = jieba.lcut(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) == 2 and word.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "# 对每个message进行LDA分析并输出一个主题\n",
    "def lda_analysis_for_message(message, num_topics=1):\n",
    "    # 预处理单个message\n",
    "    processed_text = preprocess(message)\n",
    "    \n",
    "    # 创建词典和语料库\n",
    "    dictionary = corpora.Dictionary([processed_text])\n",
    "    corpus = [dictionary.doc2bow(processed_text)]\n",
    "    \n",
    "    # 如果词汇量过少，跳过该消息\n",
    "    if len(dictionary) == 0:\n",
    "        return None\n",
    "\n",
    "    # 构建LDA模型\n",
    "    lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    \n",
    "    # 获取单个主题的关键词\n",
    "    topic = lda_model.print_topics(num_words=5)[0]  # 获取一个主题\n",
    "    return topic\n",
    "\n",
    "# 打开文件进行写入\n",
    "with open('/data1/dxw_data/llm/is_agents/agents/six_hats/task5/log_lda2.txt', 'w', encoding='utf-8') as log_file:\n",
    "    # 对每个message进行LDA分析并输出结果\n",
    "    for conversation in conversation_data:\n",
    "        agent = conversation['agent']\n",
    "        message = conversation['message']\n",
    "        \n",
    "        # 对每个message进行LDA分析\n",
    "        topic = lda_analysis_for_message(message)\n",
    "        \n",
    "        # 如果LDA分析有结果，打印主题关键词并写入文件\n",
    "        if topic:\n",
    "            result = f\"\\nAgent: {agent}\\nTopic: {topic}\\n\"\n",
    "        else:\n",
    "            result = f\"\\nAgent: {agent}\\nTopic: 无法生成主题（可能文本过短或无有效词汇）\\n\"\n",
    "        \n",
    "        # 打印结果到控制台\n",
    "        print(result)\n",
    "        \n",
    "        # 将结果写入文件\n",
    "        log_file.write(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
